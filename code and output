ðŸ“ŠSales Forecasting Project

# 1. Library Imports
import pandas as pd
import numpy as np
import seaborn as sns
import matplotlib.pyplot as plt

from sklearn.model_selection import train_test_split
from sklearn.linear_model import LinearRegression, Ridge
from sklearn.ensemble import RandomForestRegressor
from sklearn.metrics import mean_squared_error, r2_score
from sklearn.preprocessing import LabelEncoder, StandardScaler

import warnings
warnings.filterwarnings('ignore')
%matplotlib inline

# 2. Data Loading and Inspection
df = pd.read_csv("Train.csv")
print("Shape of ", df.shape)
print(df.head())
Shape of  (8523, 12)
  Item_Identifier  Item_Weight Item_Fat_Content  Item_Visibility  \
0           FDA15         9.30          Low Fat         0.016047   
1           DRC01         5.92          Regular         0.019278   
2           FDN15        17.50          Low Fat         0.016760   
3           FDX07        19.20          Regular         0.000000   
4           NCD19         8.93          Low Fat         0.000000   

               Item_Type  Item_MRP Outlet_Identifier  \
0                  Dairy  249.8092            OUT049   
1            Soft Drinks   48.2692            OUT018   
2                   Meat  141.6180            OUT049   
3  Fruits and Vegetables  182.0950            OUT010   
4              Household   53.8614            OUT013   

   Outlet_Establishment_Year Outlet_Size Outlet_Location_Type  \
0                       1999      Medium               Tier 1   
1                       2009      Medium               Tier 3   
2                       1999      Medium               Tier 1   
3                       1998         NaN               Tier 3   
4                       1987        High               Tier 3   

         Outlet_Type  Item_Outlet_Sales  
0  Supermarket Type1          3735.1380  
1  Supermarket Type2           443.4228  
2  Supermarket Type1          2097.2700  
3      Grocery Store           732.3800  
4  Supermarket Type1           994.7052  

# 3. Data Cleaning
df['Item_Weight'] = df.groupby('Item_Identifier')['Item_Weight'].transform(lambda x: x.fillna(x.mean()))
df['Item_Weight'].fillna(df['Item_Weight'].mean(), inplace=True)

df['Outlet_Size'] = df.groupby('Outlet_Type')['Outlet_Size'].transform(
    lambda x: x.fillna(x.mode().iloc[0] if not x.mode().empty else np.nan)
)
df['Outlet_Size'].fillna(df['Outlet_Size'].mode()[0], inplace=True)

df.loc[df['Item_Visibility'] == 0, 'Item_Visibility'] = df['Item_Visibility'].median()

fat_map = {'LF':'Low Fat', 'low fat':'Low Fat', 'reg':'Regular'}
df['Item_Fat_Content'] = df['Item_Fat_Content'].replace(fat_map)

# 4. Feature Engineering
df['New_Item_Type'] = df['Item_Identifier'].apply(lambda x: x[:2]).map({'FD':'Food', 'NC':'Non-Consumable', 'DR':'Drinks'})
df.loc[df['New_Item_Type'] == 'Non-Consumable', 'Item_Fat_Content'] = 'Non-Edible'
df['Outlet_Years'] = 2024 - df['Outlet_Establishment_Year']
outlet_avg = df.groupby('Outlet_Identifier')['Item_Outlet_Sales'].mean().to_dict()
df['Outlet_Avg_Sales'] = df['Outlet_Identifier'].map(outlet_avg)

# 5. Encoding and Feature Preparation
le = LabelEncoder()
df['Outlet'] = le.fit_transform(df['Outlet_Identifier'])

cat_cols = ['Item_Fat_Content', 'Item_Type', 'Outlet_Size', 'Outlet_Location_Type', 'Outlet_Type', 'New_Item_Type']
for col in cat_cols:
    df[col] = le.fit_transform(df[col])

df = pd.get_dummies(df, columns=['Outlet_Type', 'Outlet_Size', 'Outlet_Location_Type', 'Item_Fat_Content', 'New_Item_Type'], dtype=int)

num_cols = ['Item_Weight', 'Item_Visibility', 'Item_MRP', 'Outlet_Years', 'Outlet_Avg_Sales']
scaler = StandardScaler()
df[num_cols] = scaler.fit_transform(df[num_cols])

# 6. Modeling Data Setup
X = df.drop(columns=['Item_Identifier', 'Outlet_Identifier', 'Outlet_Establishment_Year', 'Item_Outlet_Sales'])
y = np.log1p(df['Item_Outlet_Sales'])

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)

# 7. Modeling and Evaluation

# Linear Regression
lr = LinearRegression()
lr.fit(X_train, y_train)
y_pred_lr = lr.predict(X_test)
print("Linear Regression R2:", r2_score(y_test, y_pred_lr))
print("Linear Regression RMSE:", np.sqrt(mean_squared_error(y_test, y_pred_lr)))

# Ridge Regression
ridge = Ridge(alpha=1.0)
ridge.fit(X_train, y_train)
y_pred_ridge = ridge.predict(X_test)
print("Ridge R2:", r2_score(y_test, y_pred_ridge))
print("Ridge RMSE:", np.sqrt(mean_squared_error(y_test, y_pred_ridge)))

# Random Forest
rf = RandomForestRegressor(n_estimators=100, random_state=42)
rf.fit(X_train, y_train)
y_pred_rf = rf.predict(X_test)
print("Random Forest R2:", r2_score(y_test, y_pred_rf))
print("Random Forest RMSE:", np.sqrt(mean_squared_error(y_test, y_pred_rf)))
Linear Regression R2: 0.7268441968675861
Linear Regression RMSE: 0.5366718218422112
Ridge R2: 0.7269165335639305
Ridge RMSE: 0.5366007568371078
Random Forest R2: 0.7177186666946767
Random Forest RMSE: 0.545562684126902

# 8. Results Table
print("\n=== Results Comparison ===")
print("Model              R2 Score     RMSE")
print("Linear Regression  {:.4f}      {:.4f}".format(r2_score(y_test, y_pred_lr), np.sqrt(mean_squared_error(y_test, y_pred_lr))))
print("Ridge Regression   {:.4f}      {:.4f}".format(r2_score(y_test, y_pred_ridge), np.sqrt(mean_squared_error(y_test, y_pred_ridge))))
print("Random Forest      {:.4f}      {:.4f}".format(r2_score(y_test, y_pred_rf), np.sqrt(mean_squared_error(y_test, y_pred_rf))))

=== Results Comparison ===
Model              R2 Score     RMSE
Linear Regression  0.7268      0.5367
Ridge Regression   0.7269      0.5366
Random Forest      0.7177      0.5456

# 9. Visualization Example
plt.figure(figsize=(8, 5))
plt.scatter(np.expm1(y_test), np.expm1(y_pred_rf), alpha=0.5)
plt.xlabel("Actual Sales")
plt.ylabel("Predicted Sales")
plt.title("Random Forest: Actual vs Predicted Sales")
plt.plot([0, max(np.expm1(y_test))], [0, max(np.expm1(y_test))], 'r--')
plt.show()
No description has been provided for this image